{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17604ce4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "### Step 1: Import all necessary libraries used for data processing, text embeddings, and model training\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e68835b",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 2: Set the random seed, choose the compute device, and load all training/testing data and metric embeddings\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "DATA_DIR = Path(\"data\") \n",
        "\n",
        "with open(f\"{DATA_DIR}/train_data.json\", encoding='utf-8') as f:\n",
        "    train_data = json.load(f)\n",
        "with open(f\"{DATA_DIR}/test_data.json\", encoding='utf-8') as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "metric_emb_matrix = np.load(f\"{DATA_DIR}/metric_name_embeddings.npy\")\n",
        "with open(f\"{DATA_DIR}/metric_names.json\") as f:\n",
        "    metric_names_obj = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe506340-bb7c-4cb3-ae3e-3edb4877696c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "234279e1f96a42798441f9f41a59c7f2",
            "13edcbfbbe974dd6a9f945e3aee0fa52"
          ]
        },
        "id": "fe506340-bb7c-4cb3-ae3e-3edb4877696c",
        "outputId": "a988a71a-6f40-442c-ac84-8c307559c54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Training samples: 5000\n",
            "Pseudo-labeled samples: 2742\n",
            "Total training: 7742\n",
            "\n",
            "Encoding with MiniLM...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "234279e1f96a42798441f9f41a59c7f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/121 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13edcbfbbe974dd6a9f945e3aee0fa52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training attention-based regressor...\n",
            "Epoch 5: Train Loss = 8.4894, Val RMSE = 2.8611\n",
            "Epoch 10: Train Loss = 6.3938, Val RMSE = 2.5065\n",
            "Epoch 15: Train Loss = 3.6127, Val RMSE = 2.3141\n",
            "Epoch 20: Train Loss = 2.7446, Val RMSE = 2.2710\n",
            "Epoch 25: Train Loss = 1.8927, Val RMSE = 2.2001\n",
            "Epoch 30: Train Loss = 1.5793, Val RMSE = 2.1381\n",
            "Epoch 35: Train Loss = 1.3779, Val RMSE = 2.1513\n",
            "Epoch 40: Train Loss = 1.2318, Val RMSE = 2.1165\n",
            "Epoch 45: Train Loss = 1.1054, Val RMSE = 2.0843\n",
            "Early stopping at epoch 48\n",
            "\n",
            "Best validation RMSE: 2.0581\n",
            "\n",
            "Test predictions:\n",
            "  Mean: 6.35\n",
            "  Std: 3.01\n",
            "  Range: [1.8, 8.9]\n",
            "\n",
            "Distribution:\n",
            "  0-3: 1140 (31.3%)\n",
            "  4-7: 153 (4.2%)\n",
            "  8-10: 2165 (59.5%)\n",
            "\n",
            "Submission saved to: submission.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1101070/4165061824.py:254: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_attention_model.pt'))\n"
          ]
        }
      ],
      "source": [
        "### Step 3: Cleaning Metric Names and Building Text Processing Utilities\n",
        "\n",
        "def clean_name(x):\n",
        "    if isinstance(x, list) and len(x) > 0:\n",
        "        x = x[0]\n",
        "    return str(x).strip()\n",
        "\n",
        "if isinstance(metric_names_obj, list):\n",
        "    name_to_idx = {clean_name(n): i for i, n in enumerate(metric_names_obj)}\n",
        "else:\n",
        "    name_to_idx = {clean_name(k): int(v) for k, v in metric_names_obj.items()}\n",
        "\n",
        "def find_key(options, record):\n",
        "    for opt in options:\n",
        "        if opt in record:\n",
        "            return record[opt]\n",
        "    return \"\"\n",
        "\n",
        "def build_text(item):\n",
        "    metric = item.get('metric_name', '')\n",
        "    prompt = find_key(['prompt', 'input', 'query', 'question'], item)\n",
        "    system = find_key(['system_prompt', 'instruction', 'system', 'context'], item)\n",
        "    response = find_key(['expected_response', 'response', 'answer', 'output'], item)\n",
        "\n",
        "    parts = [f\"[M] {metric}\", f\"[P] {prompt}\", f\"[S] {system}\", f\"[R] {response}\"]\n",
        "    return \" \".join(parts)\n",
        "\n",
        "### Step 4: Build Training & Pseudo-Training Data and Prepare Text Embeddings\n",
        "train_texts = [build_text(d) for d in train_data]\n",
        "train_scores = np.array([float(find_key(['score', 'target', 'fitness', 'label'], d)) for d in train_data])\n",
        "train_metric_names = [d['metric_name'] for d in train_data]\n",
        "\n",
        "test_texts = [build_text(d) for d in test_data]\n",
        "test_metric_names = [d['metric_name'] for d in test_data]\n",
        "\n",
        "pseudo_df = pd.read_csv(\"submission_minilm_embedder.csv\")\n",
        "pseudo_scores = pseudo_df['score'].values\n",
        "\n",
        "high_conf_mask = (pseudo_scores <= 2.0) | (pseudo_scores >= 8.0)\n",
        "high_conf_idx = np.where(high_conf_mask)[0]\n",
        "\n",
        "pseudo_texts = [test_texts[i] for i in high_conf_idx]\n",
        "pseudo_scores_selected = pseudo_scores[high_conf_idx]\n",
        "pseudo_metric_names = [test_metric_names[i] for i in high_conf_idx]\n",
        "\n",
        "combined_texts = train_texts + pseudo_texts\n",
        "combined_scores = np.concatenate([train_scores, pseudo_scores_selected])\n",
        "combined_metric_names = train_metric_names + pseudo_metric_names\n",
        "\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Pseudo-labeled samples: {len(pseudo_texts)}\")\n",
        "print(f\"Total training: {len(combined_texts)}\")\n",
        "\n",
        "print(\"\\nEncoding with MiniLM...\")\n",
        "encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "### Step 5: Generate Text & Metric Embeddings and Prepare Train/Validation Splits\n",
        "train_embeddings = encoder.encode(combined_texts, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
        "test_embeddings = encoder.encode(test_texts, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "train_metric_indices = [name_to_idx[clean_name(m)] for m in combined_metric_names]\n",
        "test_metric_indices = [name_to_idx[clean_name(m)] for m in test_metric_names]\n",
        "\n",
        "train_metric_embs = metric_emb_matrix[train_metric_indices]\n",
        "test_metric_embs = metric_emb_matrix[test_metric_indices]\n",
        "\n",
        "if train_metric_embs.shape[1] > train_embeddings.shape[1]:\n",
        "    train_metric_embs = train_metric_embs[:, :train_embeddings.shape[1]]\n",
        "    test_metric_embs = test_metric_embs[:, :test_embeddings.shape[1]]\n",
        "elif train_metric_embs.shape[1] < train_embeddings.shape[1]:\n",
        "    pad_width = train_embeddings.shape[1] - train_metric_embs.shape[1]\n",
        "    train_metric_embs = np.pad(train_metric_embs, ((0, 0), (0, pad_width)), mode='constant')\n",
        "    test_metric_embs = np.pad(test_metric_embs, ((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "X_train_text = train_embeddings.astype(np.float32)\n",
        "X_train_metric = train_metric_embs.astype(np.float32)\n",
        "y_train = combined_scores.astype(np.float32)\n",
        "\n",
        "X_test_text = test_embeddings.astype(np.float32)\n",
        "X_test_metric = test_metric_embs.astype(np.float32)\n",
        "\n",
        "X_tr_text, X_val_text, X_tr_metric, X_val_metric, y_tr, y_val = train_test_split(\n",
        "    X_train_text, X_train_metric, y_train, test_size=0.15, random_state=SEED\n",
        ")\n",
        "\n",
        "### Step 6: Create the Dataset Class and Define a Cross-Attention Layer\n",
        "class ScoreDataset(Dataset):\n",
        "    def __init__(self, text_emb, metric_emb, scores):\n",
        "        self.text = torch.FloatTensor(text_emb)\n",
        "        self.metric = torch.FloatTensor(metric_emb)\n",
        "        self.scores = torch.FloatTensor(scores)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.scores)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.text[idx], self.metric[idx], self.scores[idx]\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.dim = dim\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(dim, dim)\n",
        "        self.k_proj = nn.Linear(dim, dim)\n",
        "        self.v_proj = nn.Linear(dim, dim)\n",
        "        self.out_proj = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, query, key_value):\n",
        "        B = query.size(0)\n",
        "\n",
        "        Q = self.q_proj(query).view(B, 1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.k_proj(key_value).view(B, 1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v_proj(key_value).view(B, 1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn_weights = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, V)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, self.dim)\n",
        "\n",
        "        return self.out_proj(attn_output)\n",
        "    \n",
        "### Step 7: Build the Attention-Based Regressor Model\n",
        "class AttentionRegressor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, num_heads=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.text_proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.metric_proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.cross_attn_1 = CrossAttention(hidden_dim, num_heads)\n",
        "        self.cross_attn_2 = CrossAttention(hidden_dim, num_heads)\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 3, 768),\n",
        "            nn.LayerNorm(768),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(768, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, text_emb, metric_emb):\n",
        "        text_feat = self.text_proj(text_emb)\n",
        "        metric_feat = self.metric_proj(metric_emb)\n",
        "\n",
        "        text_attended = self.cross_attn_1(text_feat, metric_feat)\n",
        "        metric_attended = self.cross_attn_2(metric_feat, text_feat)\n",
        "\n",
        "        combined = torch.cat([text_feat, text_attended, metric_attended], dim=1)\n",
        "\n",
        "        output = self.fusion(combined)\n",
        "        return output.squeeze()\n",
        "    \n",
        "### Step 8: Train the Attention-Based Regressor With Early Stopping and Learning-Rate Scheduling\n",
        "train_dataset = ScoreDataset(X_tr_text, X_tr_metric, y_tr)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=False)\n",
        "\n",
        "model = AttentionRegressor(X_train_text.shape[1], hidden_dim=512, num_heads=4).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "X_val_text_t = torch.FloatTensor(X_val_text).to(device)\n",
        "X_val_metric_t = torch.FloatTensor(X_val_metric).to(device)\n",
        "\n",
        "best_val_rmse = float('inf')\n",
        "patience = 0\n",
        "max_patience = 10\n",
        "\n",
        "print(\"\\nTraining attention-based regressor...\")\n",
        "for epoch in range(60):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for text_batch, metric_batch, score_batch in train_loader:\n",
        "        text_batch = text_batch.to(device)\n",
        "        metric_batch = metric_batch.to(device)\n",
        "        score_batch = score_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text_batch, metric_batch)\n",
        "        loss = criterion(predictions, score_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_predictions = model(X_val_text_t, X_val_metric_t).cpu().numpy()\n",
        "        val_rmse = sqrt(mean_squared_error(y_val, val_predictions))\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}, Val RMSE = {val_rmse:.4f}\")\n",
        "\n",
        "    if val_rmse < best_val_rmse:\n",
        "        best_val_rmse = val_rmse\n",
        "        patience = 0\n",
        "        torch.save(model.state_dict(), 'best_attention_model.pt')\n",
        "    else:\n",
        "        patience += 1\n",
        "        if patience >= max_patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "print(f\"\\nBest validation RMSE: {best_val_rmse:.4f}\")\n",
        "\n",
        "### Step 9: Run the Best Model on Test Data, Adjust Scores, and Create the Submission File\n",
        "model.load_state_dict(torch.load('best_attention_model.pt'))\n",
        "model.eval()\n",
        "\n",
        "X_test_text_t = torch.FloatTensor(X_test_text).to(device)\n",
        "X_test_metric_t = torch.FloatTensor(X_test_metric).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_predictions = model(X_test_text_t, X_test_metric_t).cpu().numpy()\n",
        "\n",
        "test_predictions = np.clip(test_predictions, 0, 10)\n",
        "\n",
        "score_ranges = [(0, 2.5), (2.5, 5.5), (5.5, 7.5), (7.5, 10)]\n",
        "for low, high in score_ranges:\n",
        "    mask = (test_predictions >= low) & (test_predictions < high)\n",
        "    if mask.sum() > 0:\n",
        "        offset = (y_val[(val_predictions >= low) & (val_predictions < high)] -\n",
        "                 val_predictions[(val_predictions >= low) & (val_predictions < high)]).mean()\n",
        "        if not np.isnan(offset):\n",
        "            test_predictions[mask] += offset\n",
        "\n",
        "test_predictions = np.clip(test_predictions, 0, 10)\n",
        "test_predictions = np.round(test_predictions, 1)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": range(1, len(test_predictions) + 1),\n",
        "    \"score\": test_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"\\nTest predictions:\")\n",
        "print(f\"  Mean: {test_predictions.mean():.2f}\")\n",
        "print(f\"  Std: {test_predictions.std():.2f}\")\n",
        "print(f\"  Range: [{test_predictions.min():.1f}, {test_predictions.max():.1f}]\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(f\"  0-3: {(test_predictions <= 3).sum()} ({100*(test_predictions <= 3).sum()/len(test_predictions):.1f}%)\")\n",
        "print(f\"  4-7: {((test_predictions > 3) & (test_predictions <= 7)).sum()} ({100*((test_predictions > 3) & (test_predictions <= 7)).sum()/len(test_predictions):.1f}%)\")\n",
        "print(f\"  8-10: {(test_predictions >= 8).sum()} ({100*(test_predictions >= 8).sum()/len(test_predictions):.1f}%)\")\n",
        "\n",
        "print(\"\\nSubmission saved to: submission.csv\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
